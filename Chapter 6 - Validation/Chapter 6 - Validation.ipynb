{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>275</th>\n",
       "      <th>276</th>\n",
       "      <th>277</th>\n",
       "      <th>278</th>\n",
       "      <th>279</th>\n",
       "      <th>280</th>\n",
       "      <th>281</th>\n",
       "      <th>282</th>\n",
       "      <th>283</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>99679.361798</td>\n",
       "      <td>112279.02</td>\n",
       "      <td>87500.0</td>\n",
       "      <td>123600.0</td>\n",
       "      <td>88000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>215512.586019</td>\n",
       "      <td>213242.84</td>\n",
       "      <td>185128.0</td>\n",
       "      <td>201000.0</td>\n",
       "      <td>222000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>190792.974301</td>\n",
       "      <td>204017.96</td>\n",
       "      <td>195725.0</td>\n",
       "      <td>160200.0</td>\n",
       "      <td>181000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>109232.674230</td>\n",
       "      <td>122006.03</td>\n",
       "      <td>92100.0</td>\n",
       "      <td>98500.0</td>\n",
       "      <td>86000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>194048.748934</td>\n",
       "      <td>188090.20</td>\n",
       "      <td>162021.8</td>\n",
       "      <td>194700.0</td>\n",
       "      <td>178000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 285 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9   ...    275  276  277  \\\n",
       "0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  1.0  0.0  0.0   ...    0.0  0.0  0.0   \n",
       "1  0.0  0.0  0.0  1.0  0.0  0.0  1.0  1.0  0.0  0.0   ...    0.0  0.0  0.0   \n",
       "2  0.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  0.0   ...    0.0  0.0  0.0   \n",
       "3  0.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0   ...    0.0  0.0  0.0   \n",
       "4  0.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  0.0   ...    0.0  0.0  0.0   \n",
       "\n",
       "    278     279            280        281       282       283       y  \n",
       "0   6.0  2006.0   99679.361798  112279.02   87500.0  123600.0   88000  \n",
       "1  12.0  2009.0  215512.586019  213242.84  185128.0  201000.0  222000  \n",
       "2   5.0  2009.0  190792.974301  204017.96  195725.0  160200.0  181000  \n",
       "3   5.0  2009.0  109232.674230  122006.03   92100.0   98500.0   86000  \n",
       "4   6.0  2009.0  194048.748934  188090.20  162021.8  194700.0  178000  \n",
       "\n",
       "[5 rows x 285 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house_prices_reg = pd.read_csv('houseprices_regression.csv')\n",
    "house_prices_reg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Emb_C</th>\n",
       "      <th>Emb_Q</th>\n",
       "      <th>Emb_S</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  Sex   Age  SibSp  Parch     Fare  Emb_C  Emb_Q  Emb_S  Survived\n",
       "0       3    0  22.0      1      0   7.2500      0      0      1         0\n",
       "1       1    0  38.0      1      0  71.2833      1      0      0         1\n",
       "2       3    0  26.0      0      0   7.9250      0      0      1         1\n",
       "3       1    0  35.0      1      0  53.1000      0      0      1         1\n",
       "4       3    0  35.0      0      0   8.0500      0      0      1         0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_clf = pd.read_csv('titanic_classification.csv')\n",
    "titanic_clf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the models required for this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/base.py:253: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.20.2 when using version 0.20.3. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/base.py:253: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 0.20.2 when using version 0.20.3. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "with open('../Saved Models/stacked_linear_regression.pkl', 'rb') as f:\n",
    "    reg = pickle.load(f)\n",
    "    \n",
    "with open('../Saved Models/random_forest_clf.pkl', 'rb') as f:\n",
    "    rf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1: Calculating MAE & RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = house_prices_reg.drop(columns=['y'])\n",
    "y = house_prices_reg['y'].values\n",
    "\n",
    "y_pred = reg.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error = 12567.358027367643\n",
      "Root Mean Squared Error = 19256.557656417794\n",
      "R Squared Score = 0.9384546350842587\n"
     ]
    }
   ],
   "source": [
    "print('Mean Absolute Error = {}'.format(mean_absolute_error(y, y_pred)))\n",
    "print('Root Mean Squared Error = {}'.format(sqrt(mean_squared_error(y, y_pred))))\n",
    "print('R Squared Score = {}'.format(r2_score(y, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2: Calculating Accuracy, Precision, Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (accuracy_score, confusion_matrix, precision_score,\n",
    "                             recall_score, f1_score, precision_recall_curve)\n",
    "from sklearn.utils.fixes import signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = titanic_clf.iloc[:, :-1].values\n",
    "y = titanic_clf.iloc[:, -1].values\n",
    "\n",
    "y_pred = rf.predict(X)\n",
    "y_pred_probs = rf.predict_proba(X)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score = 0.6251402918069585\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy Score = {}'.format(accuracy_score(y, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[548   1]\n",
      " [333   9]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_pred=y_pred, y_true=y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Score = 0.9\n",
      "Recall Score = 0.02631578947368421\n"
     ]
    }
   ],
   "source": [
    "print('Precision Score = {}'.format(precision_score(y, y_pred)))\n",
    "print('Recall Score = {}'.format(recall_score(y, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score = 0.05113636363636364\n"
     ]
    }
   ],
   "source": [
    "print('F1 Score = {}'.format(f1_score(y, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4: k-Fold Cross Validation with Stratified Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = titanic_clf.iloc[:, :-1].values\n",
    "y = titanic_clf.iloc[:, -1].values\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6145251396648045,\n",
       " 0.6983240223463687,\n",
       " 0.7471910112359551,\n",
       " 0.7808988764044944,\n",
       " 0.711864406779661]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "for train_index, val_index in skf.split(X, y):\n",
    "    X_train, X_val = X[train_index], X[val_index]\n",
    "    y_train, y_val = y[train_index], y[val_index]\n",
    "    \n",
    "    rf_skf = RandomForestClassifier(**rf.get_params())\n",
    "    \n",
    "    rf_skf.fit(X_train, y_train)\n",
    "    y_pred = rf_skf.predict(X_val)\n",
    "    \n",
    "    scores.append(accuracy_score(y_val, y_pred))\n",
    "    \n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy Score = 0.7105606912862568\n"
     ]
    }
   ],
   "source": [
    "print('Mean Accuracy Score = {}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4: Hyperparameter tuning with Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = titanic_clf.iloc[:, :-1].values\n",
    "y = titanic_clf.iloc[:, -1].values\n",
    "\n",
    "rf_rand = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(results, max_rank=3):\n",
    "    for rank in range(1, max_rank+1):\n",
    "        results_at_rank = np.flatnonzero(results['rank_test_score'] == i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {\"n_estimators\": list(range(10,210,10)),\n",
    "              \"max_depth\": list(range(3,20)),\n",
    "              \"max_features\": list(range(1, 10)),\n",
    "              \"min_samples_split\": list(range(2, 11)),\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "          estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "          fit_params=None, iid='warn', n_iter=60, n_jobs=None,\n",
       "          param_distributions={'n_estimators': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, 160, 170, 180, 190, 200], 'max_depth': [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], 'max_features': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10], 'bootstrap': [True, False], 'criterion': ['gini', 'entropy']},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score='warn', scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_iter_search = 60\n",
    "random_search = RandomizedSearchCV(rf_rand, param_distributions=param_dist, scoring='accuracy',\n",
    "                                   n_iter=n_iter_search, cv=5)\n",
    "random_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model rank: 1\n",
      "Mean validation score: 0.724 (std: 0.045)\n",
      "Model Hyperparameters: {'n_estimators': 70, 'min_samples_split': 8, 'max_features': 2, 'max_depth': 10, 'criterion': 'gini', 'bootstrap': True}\n",
      "\n",
      "Model rank: 2\n",
      "Mean validation score: 0.719 (std: 0.051)\n",
      "Model Hyperparameters: {'n_estimators': 180, 'min_samples_split': 7, 'max_features': 7, 'max_depth': 8, 'criterion': 'gini', 'bootstrap': True}\n",
      "\n",
      "Model rank: 2\n",
      "Mean validation score: 0.719 (std: 0.060)\n",
      "Model Hyperparameters: {'n_estimators': 160, 'min_samples_split': 7, 'max_features': 6, 'max_depth': 7, 'criterion': 'gini', 'bootstrap': True}\n",
      "\n",
      "Model rank: 4\n",
      "Mean validation score: 0.718 (std: 0.046)\n",
      "Model Hyperparameters: {'n_estimators': 200, 'min_samples_split': 5, 'max_features': 1, 'max_depth': 8, 'criterion': 'gini', 'bootstrap': False}\n",
      "\n",
      "Model rank: 5\n",
      "Mean validation score: 0.717 (std: 0.055)\n",
      "Model Hyperparameters: {'n_estimators': 10, 'min_samples_split': 3, 'max_features': 2, 'max_depth': 6, 'criterion': 'gini', 'bootstrap': True}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame(random_search.cv_results_).sort_values('rank_test_score')\n",
    "for i, row in results.head().iterrows():\n",
    "    print(\"Model rank: {}\".format(row.rank_test_score))\n",
    "    print(\"Mean validation score: {:.3f} (std: {:.3f})\".format(row.mean_test_score, row.std_test_score))\n",
    "    print(\"Model Hyperparameters: {}\\n\".format(row.params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank: 1\n",
      "Mean validation score: 0.727 (std: 0.052)\n",
      "Parameters: {'n_estimators': 200, 'min_samples_split': 6, 'max_features': 3, 'max_depth': 7, 'criterion': 'entropy', 'bootstrap': True}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.721 (std: 0.039)\n",
      "Parameters: {'n_estimators': 140, 'min_samples_split': 10, 'max_features': 2, 'max_depth': 10, 'criterion': 'gini', 'bootstrap': True}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.719 (std: 0.055)\n",
      "Parameters: {'n_estimators': 170, 'min_samples_split': 5, 'max_features': 9, 'max_depth': 6, 'criterion': 'entropy', 'bootstrap': True}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.719 (std: 0.045)\n",
      "Parameters: {'n_estimators': 190, 'min_samples_split': 10, 'max_features': 3, 'max_depth': 8, 'criterion': 'gini', 'bootstrap': True}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report(random_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 5: Feature importance using Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imps = pd.DataFrame({'importance': rf.feature_importances_}, index=titanic_clf.columns[:-1])\n",
    "feat_imps.sort_values(by='importance', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feat_imps.plot(kind='bar', figsize=(10,7))\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
